---
title: "Assignment_1"
author: "Patti Geppert"
date: "6/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ISLR)
```

## Assignment 1
Chapter 2: 2,5,6,8-10

Question 2:

Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.

(a) We collect a set of data on the top 500 firms in the US. For each
firm we record profit, number of employees, industry and the
CEO salary. We are interested in understanding which factors
affect CEO salary.

Regression problem; Inference; n = 500;p= 3 (profit, number of employees, industry)


(b) We are considering launching a new product and wish to know
whether it will be a success or a failure. We collect data on 20
similar products that were previously launched. For each product we have recorded whether it was a success or failure, price
charged for the product, marketing budget, competition price,
and ten other variables.


Classification problem; prediction, n=20, p= 13 (price, marketing budget, competition price + 10 other variables)

(c) We are interested in predicting the % change in the USD/Euro
exchange rate in relation to the weekly changes in the world
stock markets. Hence we collect weekly data for all of 2012. For
each week we record the % change in the USD/Euro, the %
change in the US market, the % change in the British market,
and the % change in the German market.

Regression problem; prediction; n= 52, p = 3 (% change in US market, % change in British market, % change in German Market)


5. What are the advantages and disadvantages of a very flexible (versus
a less flexible) approach for regression or classification? Under what
circumstances might a more flexible approach be preferred to a less
flexible approach? When might a less flexible approach be preferred?

Advantages of Flexible approach:
1.  Does not make assumptions about the relationship in the data, just tries to find a data that minimizes reducible error so it can fit a wider range of model shapes.
2.  Can be very good for predictive models
3.  Tends to reduce bias

Disadvantages of Flexible approach:
1.  Requires a lot of data points to fit model
2.  Overfitting may occur with very flexible model.  The result is a model that fits the training data well, but not the test data.
3.  Difficult to interpret so not good for inferential questions.
4.  Tends to increase variance

Advantages of less flexible models 
1.  Makes assumptions about relationships in the data, the functional form of the model, so there are fewer parameters to estimate.
2.  Requires less data to fit the model
3.  Tends to decrease variance
4.  Better interpretability therefore good for inferential questions

Disadvantages of less flexible models:
1.  May not make good predictive models
2.  Tends to increase bias

Very Flexible models tend to be good for predictive modeling
Less Flexible models tend to be good for inferential modeling

6. Describe the differences between a parametric and a non-parametric
statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a nonparametric approach)? What are its disadvantages?

Parametric statistical learning approaches make assumptions about the form of the true model so it reduces the problem down to estimating a few parameters.  As such, parametric models are not very flexible   Non-parametric statistical learning does not make assumptions about the form of the true model, they just try to find the model with the least reducible error.  AS such, non-parametric models are much more flexible.

The advantages of parametric over non-parametric is that they require less data to fit the model and they are easier to interpret (i.e. explain predictor variable effect on the outcome).  Therefore parametric approaches are better for inference models.  It is more difficult to interpret non-parametric models because the form of the model is not consistent.  However, non-parametric models tend to be good for predictive modeling.

8. This exercise relates to the College data set, which can be found in
the file College.csv. It contains a number of variables for 777 different
universities and colleges in the US. The variables are
• Private : Public/private indicator
• Apps : Number of applications received
• Accept : Number of applicants accepted
• Enroll : Number of new students enrolled
• Top10perc : New students from top 10 % of high school class
• Top25perc : New students from top 25 % of high school class
• F.Undergrad : Number of full-time undergraduates
• P.Undergrad : Number of part-time undergraduates
• Outstate : Out-of-state tuition
• Room.Board : Room and board costs
• Books : Estimated book costs
• Personal : Estimated personal spending
• PhD : Percent of faculty with Ph.D.’s
• Terminal : Percent of faculty with terminal degree
• S.F.Ratio : Student/faculty ratio
• perc.alumni : Percent of alumni who donate
• Expend : Instructional expenditure per student
• Grad.Rate : Graduation rate

Before reading the data into R, it can be viewed in Excel or a text
editor.
(a) Use the read.csv() function to read the data into R. Call the
loaded data college. Make sure that you have the directory set
to the correct location for the data

```{r}
college <- ISLR::College
str(college)
```
(b) Look at the data using the fix() function. You should notice
that the first column is just the name of each university. We don’t
really want R to treat this as data. However, it may be handy to
have these names for later. Try the following commands:




(c) i. Use the summary() function to produce a numerical summary
of the variables in the data set
```{r}
summary(college)
```
```{r}
pairs(college[,1:10])
```
```{r}
plot(college$Private,college$Outstate,xlab = 'Private Y/N', ylab = 'Outstate Tuition ($)')
```

```{r}
Elite = rep("No",nrow(college))
Elite[college$Top10perc>50] = "Yes"
Elite = as.factor(Elite)
college = data.frame(college,Elite)
summary(Elite)
```
```{r}
plot(college$Elite,college$Outstate,xlab = 'Elite College Y/N', ylab = "Outstate Tuition ($)")
```
```{r}
par(mfrow = c(2,2))
xlab = "Outstate Tuition ($)"
hist(college$Outstate, xlab = xlab)
hist(college$Outstate,breaks = 15, xlab = xlab)
hist(college$Outstate,breaks = 20, xlab = xlab)
hist(college$Outstate,breaks = 50, xlab = xlab)
```
```{r}
par(mfrow = c(2,2))
xlab = "Number of Student Enrolled"
hist(college$Enroll, xlab = xlab)
hist(college$Enroll,breaks = 15, xlab = xlab)
hist(college$Enroll,breaks = 20, xlab = xlab)
hist(college$Enroll,breaks = 50, xlab = xlab)
```
```{r}
par(mfrow = c(2,2))
xlab = "Cost of Books ($)"
hist(college$Books, xlab = xlab,main = 'Cost of Books, bins=9')
hist(college$Books,breaks = 15, xlab = xlab, main = 'Cost of Books, bins=15')
hist(college$Books,breaks = 20, xlab = xlab,main = 'Cost of Books, bins=20')
hist(college$Books,breaks = 50, xlab = xlab,main = 'Cost of Books, bins=50')
```
Continue to explore the data:
```{r}

```

9. This exercise involves the Auto data set studied in the lab. Make sure
that the missing values have been removed from the data.

```{r}
auto <- ISLR::Auto
summary(auto)
```
There are no missing values in this dataset

(a) Which of the predictors are quantitative, and which are qualitative?

Quantitative:  mpg, displacement, horsepower, weight, acceleration
Qualitative: cylinders, origin, year, name

(b) What is the range of each quantitative predictor? You can answer this using the range() function.
```{r}
range(auto$mpg)
range(auto$displacement)
range(auto$horsepower)
range(auto$weight)
range(auto$acceleration)
```



